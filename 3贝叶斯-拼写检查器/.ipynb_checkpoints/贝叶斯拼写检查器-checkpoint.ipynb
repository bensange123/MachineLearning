{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  贝叶斯拼写检查器 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, collections\n",
    " \n",
    "def words(text): return re.findall('[a-z]+', text.lower()) \n",
    " \n",
    "def train(features):\n",
    "    model = collections.defaultdict(lambda: 1)\n",
    "    for f in features:\n",
    "        model[f] += 1\n",
    "    return model\n",
    " \n",
    "NWORDS = train(words(open('big.txt').read()))\n",
    " \n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    " \n",
    "def edits1(word):\n",
    "    n = len(word)\n",
    "    return set([word[0:i]+word[i+1:] for i in range(n)] +                     # deletion\n",
    "               [word[0:i]+word[i+1]+word[i]+word[i+2:] for i in range(n-1)] + # transposition\n",
    "               [word[0:i]+c+word[i+1:] for i in range(n) for c in alphabet] + # alteration\n",
    "               [word[0:i]+c+word[i:] for i in range(n+1) for c in alphabet])  # insertion\n",
    " \n",
    "def known_edits2(word):\n",
    "    return set(e2 for e1 in edits1(word) for e2 in edits1(e1) if e2 in NWORDS)\n",
    " \n",
    "def known(words): return set(w for w in words if w in NWORDS)\n",
    " \n",
    "def correct(word):\n",
    "    candidates = known([word]) or known(edits1(word)) or known_edits2(word) or [word]\n",
    "    return max(candidates, key=lambda w: NWORDS[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'know'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#appl #appla #learw #tess #morw\n",
    "correct('knon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 详细解释"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 求解：argmaxc P(c|w) -> argmaxc P(w|c) P(c) / P(w) ###\n",
    "\n",
    "* P(c), 文章中出现一个正确拼写词 c 的概率, 也就是说, 在英语文章中, c 出现的概率有多大\n",
    "* P(w|c), 在用户想键入 c 的情况下敲成 w 的概率. 因为这个是代表用户会以多大的概率把 c 敲错成 w\n",
    "* argmaxc, 用来枚举所有可能的 c 并且选取概率最大的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把语料中的单词全部抽取出来, 转成小写, 并且去除单词中间的特殊符号\n",
    "def words(text): return re.findall('[a-z]+', text.lower()) \n",
    "#[a-z]+，+表示多次重复匹配\n",
    "#text.lower()，文本转换为小写模式\n",
    " \n",
    "#统计词频\n",
    "def train(features):\n",
    "    model = collections.defaultdict(lambda: 1) #使用collections类中的defaultdict()方法来为字典提供默认值\n",
    "    for f in features:\n",
    "        model[f] += 1\n",
    "    return model\n",
    " \n",
    "NWORDS = train(words(open('big.txt').read()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要是遇到我们从来没有过见过的新词怎么办. 假如说一个词拼写完全正确, 但是语料库中没有包含这个词, 从而这个词也永远不会出现在训练集中. 于是, 我们就要返回出现这个词的概率是0. 这个情况不太妙, 因为概率为0这个代表了这个事件绝对不可能发生, 而在我们的概率模型中, 我们期望用一个很小的概率来代表这种情况. lambda: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "展示字典里的前5个元素： [('the', 80031), ('project', 289), ('gutenberg', 264), ('ebook', 88), ('of', 40026)]\n",
      "展示前5个单词： ['the', 'project', 'gutenberg', 'ebook', 'of']\n",
      "一共有29154个不同的单词\n",
      "一共有1105232个的单词\n"
     ]
    }
   ],
   "source": [
    "print('展示字典里的前5个元素：',list(NWORDS.items())[0:5]) \n",
    "print('展示前5个单词：',re.findall('[a-z]+', open('big.txt').read().lower())[0:5])\n",
    "print('一共有{}个不同的单词'.format(len(NWORDS)))\n",
    "print('一共有{}个的单词'.format(len(re.findall('[a-z]+', open('big.txt').read().lower()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  编辑距离: ###\n",
    "两个词之间的编辑距离定义为使用了几次插入(在词中插入一个单字母), 删除(删除一个单字母), 交换(交换相邻两个字母), 替换(把一个字母换成另一个)的操作从一个词变到另一个词."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#返回所有与单词 w 编辑距离为 1 的集合\n",
    "def edits1(word):\n",
    "    n = len(word)\n",
    "    # set() 函数创建一个无序不重复元素集，用来删除重复的字符串\n",
    "    return set([word[0:i]+word[i+1:] for i in range(n)] +                     # deletion,+可以用来连接数组\n",
    "               [word[0:i]+word[i+1]+word[i]+word[i+2:] for i in range(n-1)] + # transposition\n",
    "               [word[0:i]+c+word[i+1:] for i in range(n) for c in alphabet] + # alteration，alphabet为字母表\n",
    "               [word[0:i]+c+word[i:] for i in range(n+1) for c in alphabet])  # insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#返回所有与单词 w 编辑距离为 2 的集合\n",
    "#在这些编辑距离小于2的词中间, 只把那些正确的词作为候选词\n",
    "def edits2(word):\n",
    "    return set(e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与 something 编辑距离为2的单词居然达到了 114,324 个\n",
    "\n",
    "优化:在这些编辑距离小于2的词中间, 只把那些正确的词作为候选词,只能返回 3 个单词: ‘smoothing’, ‘something’ 和 ‘soothing’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def known(words): return set(w for w in words if w in NWORDS)\n",
    "\n",
    "#如果known(set)非空, candidate 就会选取这个集合, 而不继续计算后面的\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct(word):\n",
    "    candidates = known([word]) or known(edits1(word)) or known_edits2(word) or [word]\n",
    "    #这里实际上使用编辑距离来近似于P(w|c)\n",
    "#     if len(candidates)==1 and candidates not in NWORDS:\n",
    "#         NWORDS[candidates]    \n",
    "    return max(candidates, key=lambda w: NWORDS[w])\n",
    "    #返回候选单词中词频最高的，即先验概率P(c)最大的那个"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正常来说把一个元音拼成另一个的概率要大于辅音 (因为人常常把 hello 打成 hallo 这样); 把单词的第一个字母拼错的概率会相对小, 等等.但是为了简单起见, 选择了一个简单的方法: 编辑距离为1的正确单词比编辑距离为2的优先级高, 而编辑距离为0的正确单词优先级比编辑距离为1的高. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apply'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#appl #appla #learw #tess #morw\n",
    "correct('appla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NWORDS['simesimesimesimesimesimesime']\n",
    "del NWORDS['simesimesimesimesimesimesime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试\n",
    "# txt =open('big.txt').read()\n",
    "# print(type(txt),len(txt),txt[0:50])\n",
    "# txt.lower()[0:50]\n",
    "# print(re.findall('[a-z]+', txt.lower()[0:11]) ,len(re.findall('[a-z]+', txt.lower())),len(re.findall('[a-z]+', txt.lower()[0:10])))\n",
    "# model = collections.defaultdict(lambda: 1)\n",
    "# print(len(model))\n",
    "# print(NWORDS['the'],len(NWORDS),)\n",
    "# print(len(edits1('something')),len(edits2('something'))) #494 114324\n",
    "# print(set([1,2,3]+  [2,3,4]), type(set([1,2,3] + [2,3,4]))) #{1, 2, 3, 4} <class 'set'>\n",
    "# print([1,2,3,4][0:0]) #[]\n",
    "# alphabet #'abcdefghijklmnopqrstuvwxyz'\n",
    "# model1 = collections.defaultdict(lambda: 1)\n",
    "# model1['sahdjs']\n",
    "# list(model1)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
