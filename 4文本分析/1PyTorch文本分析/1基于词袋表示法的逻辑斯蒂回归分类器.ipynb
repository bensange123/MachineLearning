{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x19328248030>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.6614,  0.2669,  0.0617,  0.6213, -0.4519])\n",
      "tensor([0.2847, 0.1919, 0.1563, 0.2735, 0.0935])\n",
      "tensor(1.)\n",
      "tensor([-1.2563, -1.6507, -1.8559, -1.2963, -2.3695])\n"
     ]
    }
   ],
   "source": [
    "# Softmax也在 torch.nn.functional\n",
    "data = autograd.Variable(torch.randn(5))\n",
    "print(data)\n",
    "print(F.softmax(data, dim=0))\n",
    "print(F.softmax(data, dim=0).sum()) #总和为一因为他是概率分布!\n",
    "print(F.log_softmax(data, dim=0)) # 他也是 log_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'it': 7, 'que': 11, 'a': 18, 'on': 25, 'lost': 21, 'Give': 6, 'not': 17, 'una': 13, 'creo': 10, 'get': 20, 'No': 9, 'gusta': 1, 'la': 4, 'idea': 15, 'sea': 12, 'good': 19, 'si': 24, 'Yo': 23, 'at': 22, 'is': 16, 'me': 0, 'to': 8, 'buena': 14, 'comer': 2, 'en': 3, 'cafeteria': 5}\n"
     ]
    }
   ],
   "source": [
    "data = [(\"me gusta comer en la cafeteria\".split(), \"SPANISH\"),\n",
    "(\"Give it to me\".split(), \"ENGLISH\"),\n",
    "(\"No creo que sea una buena idea\".split(), \"SPANISH\"),\n",
    "(\"No it is not a good idea to get lost at sea\".split(), \"ENGLISH\")]\n",
    "#print(data)\n",
    "test_data = [(\"Yo creo que si\".split(), \"SPANISH\"),\n",
    "(\"it is lost on me\".split(), \"ENGLISH\")]\n",
    "# word_to_ix 将在词汇中的单词映射为一个特征数,\n",
    "# 这个特征数就是单词在词袋中的索引\n",
    "word_to_ix = {}\n",
    "for sent, _ in data + test_data:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "print(word_to_ix)\n",
    "VOCAB_SIZE = len(word_to_ix)\n",
    "NUM_LABELS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data + test_data:\n",
      " [(['me', 'gusta', 'comer', 'en', 'la', 'cafeteria'], 'SPANISH'), (['Give', 'it', 'to', 'me'], 'ENGLISH'), (['No', 'creo', 'que', 'sea', 'una', 'buena', 'idea'], 'SPANISH'), (['No', 'it', 'is', 'not', 'a', 'good', 'idea', 'to', 'get', 'lost', 'at', 'sea'], 'ENGLISH'), (['Yo', 'creo', 'que', 'si'], 'SPANISH'), (['it', 'is', 'lost', 'on', 'me'], 'ENGLISH')]\n",
      "------------------------------------------------------------------------------------\n",
      "['me', 'gusta', 'comer', 'en', 'la', 'cafeteria'] SPANISH\n",
      "['Give', 'it', 'to', 'me'] ENGLISH\n",
      "['No', 'creo', 'que', 'sea', 'una', 'buena', 'idea'] SPANISH\n",
      "['No', 'it', 'is', 'not', 'a', 'good', 'idea', 'to', 'get', 'lost', 'at', 'sea'] ENGLISH\n",
      "['Yo', 'creo', 'que', 'si'] SPANISH\n",
      "['it', 'is', 'lost', 'on', 'me'] ENGLISH\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "print('data + test_data:\\n',data + test_data)\n",
    "print('------------------------------------------------------------------------------------')\n",
    "for sent, kind in data + test_data:\n",
    "    print(sent,kind)\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 26]) Parameter containing:\n",
      "tensor([[ 0.0716, -0.0764, -0.0143, -0.0177,  0.0284, -0.0008,  0.1714,  0.0610,\n",
      "         -0.0730, -0.1184, -0.0329, -0.0846, -0.0628,  0.0094,  0.1169,  0.1066,\n",
      "         -0.1917,  0.1216,  0.0548,  0.1860,  0.1294, -0.1787, -0.1865, -0.0946,\n",
      "          0.1722, -0.0327],\n",
      "        [ 0.0839, -0.0911,  0.1924, -0.0830,  0.1471,  0.0023, -0.1033,  0.1008,\n",
      "         -0.1041,  0.0577, -0.0566, -0.0215, -0.1885, -0.0935,  0.1064, -0.0477,\n",
      "          0.1953,  0.1572, -0.0092, -0.1309,  0.1194,  0.0609, -0.1268,  0.1274,\n",
      "          0.1191,  0.1739]], requires_grad=True)\n",
      "torch.Size([2]) Parameter containing:\n",
      "tensor([-0.1099, -0.0323], requires_grad=True)\n",
      "------------------------------------------------------------------------------------\n",
      "tensor([[-0.8766, -0.5382]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "class BoWClassifier(nn.Module): # 从 nn.Module继承!\n",
    "\n",
    "    def __init__(self, num_labels, vocab_size):\n",
    "        # 在 nn.Module中调用初始化函数. 不要被这个困惑,\n",
    "        # 这个做法经常在 nn.Module见到\n",
    "        super(BoWClassifier, self).__init__()\n",
    "\n",
    "        # 定义你需要的变量. 在本例中, 我们需要affine mapping的系数 A 和 b.\n",
    "        # Torch 定义了可提供 affine map的nn.Linear().\n",
    "        # 确定你理解了为什么输入矩阵的维度是 vocab_size而输出的是num_labels!\n",
    "        self.linear = nn.Linear(vocab_size, num_labels)\n",
    "\n",
    "        # 注意! non-linearity log softmax 没有系数!\n",
    "        # 所以我们在这并不需要担心\n",
    "\n",
    "    def forward(self, bow_vec):\n",
    "        # 将输入引入到线性神经元层中, 随后引入到log_softmax.\n",
    "        # 在torch.nn.functional中有很多非线性和其他的函数\n",
    "        return F.log_softmax(self.linear(bow_vec), dim=1)\n",
    "\n",
    "def make_bow_vector(sentence, word_to_ix):\n",
    "    vec = torch.zeros(len(word_to_ix))\n",
    "    for word in sentence:\n",
    "        vec[word_to_ix[word]] += 1\n",
    "    return vec.view(1, -1)\n",
    "\n",
    "def make_target(label, label_to_ix):\n",
    "    return torch.LongTensor([label_to_ix[label]])\n",
    "\n",
    "model = BoWClassifier(NUM_LABELS, VOCAB_SIZE)\n",
    "# model = BoWClassifier(2, 26)\n",
    "# model知道它的系数.第一个输出的是A, 第二个是b.\n",
    "# 当你在模块__init__函数中指定一个神经元去分类变量, self.linear = nn.Linear(...)被执行\n",
    "# 随后从Pytorch devs通过Python magic, 你的模块(在本例中, BoWClassifier) 将会存储 nn.Linear的系数\n",
    "for param in model.parameters():\n",
    "    print(param.size(),param)\n",
    "print('------------------------------------------------------------------------------------')\n",
    "# 要运行该模型, 请传入一个BoW vector, 但要将其封装在一个autograd.Variable中.\n",
    "sample = data[0]\n",
    "bow_vector = make_bow_vector(sample[0], word_to_ix)\n",
    "log_probs = model(autograd.Variable(bow_vector))\n",
    "print(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_to_ix = {\"SPANISH\": 0, \"ENGLISH\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8462, -0.5604]], grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([[-1.2863, -0.3234]], grad_fn=<LogSoftmaxBackward>)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0716, -0.0764, -0.0143, -0.0177,  0.0284, -0.0008,  0.1714,  0.0610,\n",
      "         -0.0730, -0.1184, -0.0329, -0.0846, -0.0628,  0.0094,  0.1169,  0.1066,\n",
      "         -0.1917,  0.1216,  0.0548,  0.1860,  0.1294, -0.1787, -0.1865, -0.0946,\n",
      "          0.1722, -0.0327],\n",
      "        [ 0.0839, -0.0911,  0.1924, -0.0830,  0.1471,  0.0023, -0.1033,  0.1008,\n",
      "         -0.1041,  0.0577, -0.0566, -0.0215, -0.1885, -0.0935,  0.1064, -0.0477,\n",
      "          0.1953,  0.1572, -0.0092, -0.1309,  0.1194,  0.0609, -0.1268,  0.1274,\n",
      "          0.1191,  0.1739]], requires_grad=True) 10\n",
      "tensor([-0.0329, -0.0566], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 在我们训练前运行训练集, 去看看前后的变化\n",
    "for instance, label in test_data:\n",
    "    bow_vec = autograd.Variable(make_bow_vector(instance, word_to_ix))\n",
    "    log_probs = model(bow_vec)\n",
    "    print(log_probs)\n",
    "# 在矩阵中输出\"creo\"列\n",
    "print(next(model.parameters()), word_to_ix[\"creo\"])\n",
    "print(next(model.parameters())[:, word_to_ix[\"creo\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.762496292591095\n",
      "0.4778616428375244\n",
      "0.33652955293655396\n",
      "0.2556207776069641\n",
      "0.2045934945344925\n",
      "0.16989722847938538\n",
      "0.14493465423583984\n",
      "0.1261860579252243\n",
      "0.1116245687007904\n",
      "0.10000835359096527\n",
      "0.09053744375705719\n",
      "0.08267492055892944\n",
      "0.07604753971099854\n",
      "0.07038846611976624\n",
      "0.06550195813179016\n",
      "0.061241328716278076\n",
      "0.05749458074569702\n",
      "0.05417466163635254\n",
      "0.051213234663009644\n",
      "0.04855555295944214\n",
      "0.04615744948387146\n",
      "0.04398295283317566\n",
      "0.042002320289611816\n",
      "0.040190935134887695\n",
      "0.03852808475494385\n",
      "0.03699636459350586\n",
      "0.035580843687057495\n",
      "0.03426888585090637\n",
      "0.033049553632736206\n",
      "0.03191351890563965\n",
      "0.030852466821670532\n",
      "0.029859274625778198\n",
      "0.028927624225616455\n",
      "0.028052061796188354\n",
      "0.027227580547332764\n",
      "0.026449978351593018\n",
      "0.02571532130241394\n",
      "0.025020241737365723\n",
      "0.024361401796340942\n",
      "0.023736268281936646\n",
      "0.023142307996749878\n",
      "0.02257716655731201\n",
      "0.02203887701034546\n",
      "0.021525532007217407\n",
      "0.021035432815551758\n",
      "0.020567119121551514\n",
      "0.020119071006774902\n",
      "0.01969003677368164\n",
      "0.019278883934020996\n",
      "0.018884509801864624\n",
      "0.01850581169128418\n",
      "0.018141955137252808\n",
      "0.017792105674743652\n",
      "0.017455488443374634\n",
      "0.017131298780441284\n",
      "0.016818910837173462\n",
      "0.016517579555511475\n",
      "0.01622694730758667\n",
      "0.015946269035339355\n",
      "0.015675097703933716\n",
      "0.015413016080856323\n",
      "0.0151594877243042\n",
      "0.014914065599441528\n",
      "0.014676541090011597\n",
      "0.014446347951889038\n",
      "0.01422339677810669\n",
      "0.014007151126861572\n",
      "0.013797342777252197\n",
      "0.013593673706054688\n",
      "0.013395905494689941\n",
      "0.013203859329223633\n",
      "0.013017147779464722\n",
      "0.012835651636123657\n",
      "0.012659192085266113\n",
      "0.012487471103668213\n",
      "0.012320339679718018\n",
      "0.012157678604125977\n",
      "0.011999130249023438\n",
      "0.0118446946144104\n",
      "0.011694252490997314\n",
      "0.011547446250915527\n",
      "0.011404454708099365\n",
      "0.01126474142074585\n",
      "0.011128485202789307\n",
      "0.01099550724029541\n",
      "0.010865628719329834\n",
      "0.010738730430603027\n",
      "0.010614871978759766\n",
      "0.010493755340576172\n",
      "0.010375440120697021\n",
      "0.010259568691253662\n",
      "0.010146498680114746\n",
      "0.01003575325012207\n",
      "0.009927451610565186\n",
      "0.009821295738220215\n",
      "0.009717583656311035\n",
      "0.009615957736968994\n",
      "0.009516417980194092\n",
      "0.009418904781341553\n",
      "0.009323477745056152\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# 通常你想要多次浏览训练集.100比起实际数据集是很多的, 但实际数据集会多于2个实例.\n",
    "# 通常, 在5到30之间是合理的.\n",
    "LOSS = []\n",
    "for epoch in range(100):\n",
    "    Loss = 0\n",
    "    for instance, label in data:\n",
    "        # 步骤 1\\. 牢记 Pytorch 会积累梯度.\n",
    "        # 我们需要在每一例前清理掉\n",
    "        model.zero_grad()\n",
    "\n",
    "        # 步骤 2\\. 制作我们的 BOW 向量 并且我们必须将目标封装在变量中并且为整数 .\n",
    "        # 例如, 如果目标是\"西班牙语\", 则封装为整数0.对于损失函数而言, 概率分布的\n",
    "        # 第0列对应的是\"西班牙语\"的损失函数.\n",
    "        #\n",
    "        bow_vec = autograd.Variable(make_bow_vector(instance, word_to_ix))\n",
    "        target = autograd.Variable(make_target(label, label_to_ix))\n",
    "\n",
    "        # 步骤 3\\. Run our forward pass.\n",
    "        log_probs = model(bow_vec)\n",
    "\n",
    "        # 步骤 4\\. 计算损失, 梯度, 通过调用optimizer.step()来更新系数\n",
    "        #\n",
    "        loss = loss_function(log_probs, target)\n",
    "        Loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    Loss = Loss/4\n",
    "    LOSS.append(Loss)\n",
    "    print(Loss.item())\n",
    "plt.plot(LOSS)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
